{
  "permissions": {
    "allow": [
      "Bash(tasklist:*)",
      "Bash(cmd.exe //c \"taskkill //F //IM node.exe\")",
      "Bash(powershell.exe -NoProfile -Command \"Stop-Process -Name node -Force -ErrorAction SilentlyContinue; Write-Host ''Done''\")",
      "Bash(powershell.exe -NoProfile -Command \"Remove-Item -Recurse -Force ''C:\\Users\\juanp\\desktop\\code\\travelers.ai\\packages\\mobile''\")",
      "Bash(powershell.exe -NoProfile -Command \"Remove-Item -Recurse -Force ''C:\\Users\\juanp\\desktop\\code\\travelers.ai\\packages\\shared''\")",
      "Bash(powershell.exe -NoProfile -Command \"if (Test-Path ''C:\\Users\\juanp\\desktop\\code\\travelers.ai\\node_modules'') { Remove-Item -Recurse -Force ''C:\\Users\\juanp\\desktop\\code\\travelers.ai\\node_modules''; Write-Host ''Removed node_modules'' } else { Write-Host ''No node_modules found'' }\")",
      "Bash(ls:*)",
      "Bash(find:*)",
      "Bash(powershell.exe -NoProfile -Command \"Expand-Archive -Force -Path ''C:\\Users\\juanp\\Desktop\\code\\travelers.ai\\tools\\llama-b7315-bin-win-cuda-13.1-x64.zip'' -DestinationPath ''C:\\Users\\juanp\\Desktop\\code\\travelers.ai\\tools\\llama-cpp-b7315''; Get-ChildItem ''C:\\Users\\juanp\\Desktop\\code\\travelers.ai\\tools\\llama-cpp-b7315'' | Select-Object Name,Length | Format-Table -AutoSize\")",
      "Bash(.llama-server.exe:*)",
      "Bash(timeout 5 curl:*)",
      "Bash(cmd.exe:*)",
      "WebFetch(domain:forums.developer.nvidia.com)",
      "Bash(powershell.exe -NoProfile -Command \"Get-Content $PROFILE -ErrorAction SilentlyContinue\")",
      "Bash(powershell.exe -NoProfile -Command:*)",
      "Bash(git init:*)",
      "Bash(git branch:*)",
      "Bash(git add:*)",
      "Bash(xargs sed:*)",
      "Bash(powershell.exe -Command \". $PROFILE; workon-list\")",
      "WebSearch",
      "Bash(cat:*)",
      "Bash(dir:*)",
      "Bash(findstr:*)",
      "Bash(\"tools\\llama-cpp-vulkan\\llama-bench.exe\":*)",
      "Bash(git clone:*)",
      "Bash(powershell.exe -ExecutionPolicy Bypass -File \"C:\\Users\\juanp\\Desktop\\code\\omen\\tools\\build-cuda.ps1\")",
      "Bash(\"tools\\llama-cpp-cuda\\build\\bin\\Release\\llama-bench.exe\":*)",
      "Bash(\"tools\\llama-cpp-cuda\\build\\bin\\Release\\llama-bench.exe\" -m \"models\\qwen3\\Qwen3-8B-Q4_K_M.gguf\" -ngl 99 -n 128 -p 512)",
      "WebFetch(domain:github.com)",
      "Bash(python -m py_compile:*)",
      "Bash(python -m pytest tests/ -v)",
      "Bash(python -m venv:*)",
      "Bash(..venvScriptspip install -e \".[dev]\")",
      "Bash(wmic path:*)",
      "Bash(.venvScriptspython -m pytest tests/test_omen_client.py -v)",
      "Bash(echo:*)",
      "Bash(PYTHONPATH=src .venv/bin/python:*)",
      "Bash(python -c:*)",
      "Bash(.venv/Scripts/pip install:*)",
      "Bash(PYTHONPATH=src .venv/Scripts/python:*)",
      "Bash(curl:*)"
    ],
    "deny": [],
    "ask": []
  }
}
